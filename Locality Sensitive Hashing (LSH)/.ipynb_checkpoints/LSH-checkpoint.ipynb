{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from nltk import ngrams\n",
    "import re\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data file couldn't be checked into github because it is too large instead it must be downloaded here #https://www.dropbox.com/s/ir6he8jxxagugnw/assignment3_aricles.json?dl=0datafile =  'data/assignment3_aricles.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_json('assignment3_aricles.json', orient='records', encoding=\"utf-8\")\n",
    "list_of_primes = np.array(pd.read_csv('primes-to-100k.txt', sep=\" \", header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can use n-gram at word level for this task\n",
    "#try with different n-gram values \n",
    "# You can use ngrams from nltk for this\n",
    "\n",
    "def getNgrams(articles,K):\n",
    "    # Param type_split : the type of splitting is it by word or number of character\n",
    "    \n",
    "    Ngrams_lists = []\n",
    "    n_articles=len(articles)\n",
    "\n",
    "    for article in articles:\n",
    "        # convert to lower case\n",
    "        article = article.lower()\n",
    "        # Replace all none alphanumeric characters with spaces\n",
    "        article = re.sub(r'[^a-zA-Z0-9\\s]', ' ', article)\n",
    "        #article = re.sub(r\"[^\\w\\s]\", ' ', article)\n",
    "        article = article.replace('\\n',' ')\n",
    "        words = [word for word in article.split(' ') if word !='']\n",
    "        length_words = len(words)\n",
    "        Ngrams_lists.append([' '.join(words[i:i+K]) for i in range(0,length_words) if i+K<=length_words])\n",
    "        \n",
    "    #return list of ngrams for each article\n",
    "    return Ngrams_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert n-grams into binary vector representation for each document. You can do some optimzations if the matrix is too big.\n",
    "For example, \n",
    "* Select top 10000 most frequent n-grams.\n",
    "* You may also try smaller values of n (like 2 or 3) which result in fewer n-grams.\n",
    "* Finally, you can also try sparse matrix representation. Like csr_matrix from  scipy.sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency(articles_ngram):\n",
    "    ngram_arrays = list(it.chain.from_iterable(articles_ngram))\n",
    "    return np.unique(ngram_arrays,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBinaryMatrix(articles_ngram):\n",
    "    #Get the frequency of appearance of each shingles\n",
    "    n_top = 10000\n",
    "\n",
    "    print('get_frequency..')\n",
    "    results = get_frequency(articles_ngram)\n",
    "    print('get_sets of articles')\n",
    "    articles_ngram_set = [set(s) for s in articles_ngram]\n",
    "    print('sorting index')\n",
    "    sorted_index = np.argsort(results[1])    \n",
    "    subset_index = sorted_index[-n_top:]\n",
    "    print('Select top 10000 most frequent n-grams')\n",
    "    subset_ngrams = [results[0][idx] for idx in subset_index]\n",
    "    print('Creating binary matrix')\n",
    "    \n",
    "    binary_matrix = {}\n",
    "    \n",
    "    count= 0\n",
    "    for h in range(len(subset_ngrams)):\n",
    "        for i in range(len(articles_ngram)):\n",
    "            if subset_ngrams[h] in articles_ngram_set[i]:\n",
    "                if h in binary_matrix:\n",
    "                    binary_matrix[h].append(i)\n",
    "                else:\n",
    "                    binary_matrix[h] = [i]\n",
    "    \n",
    "    return binary_matrix,n_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need hash function that maps integers 0, 1, . . . , k − 1 to bucket numbers 0 through k − 1. It might be impossible to avoid collisions but as long as the collions are too many it won't matter much.\n",
    "\n",
    "* The simplest would be using the builtin hash() function, it can be for example, hash(rownumber) % Numberofbuckets\n",
    "* You can generate several of these hash functions by xoring a random integer (hash(rownumber)^randint) % Numberofbuckets\n",
    "* It can also be a as simple as (rownumber * randint) % Numberofbuckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Hash Eq\n",
    "The coefficients a and b are randomly chosen integers less than the maximum value of x. c is a prime number slightly bigger than the maximum value of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_prime(number):\n",
    "    return list_of_primes[list_of_primes>number][0]\n",
    "    #l = [*range(num, (2*num)+1)]\n",
    "    #primes = []\n",
    "    #for i in l:\n",
    "    #    if all([i % n for n in range(2, i)]):\n",
    "    #    primes.append(i)\n",
    "        \n",
    "    #return (min(primes))\n",
    "\n",
    "def getHashFunctionValues(numrows, numhashfunctions=200):\n",
    "    #return a matrix with hash values\n",
    "    hashvalues = []\n",
    "    \n",
    "    #using universal hash function ax+b mod c\n",
    "    #a is any odd number between 1 to next_prime-1(inclusive)\n",
    "    #b is any number between 0 to next_prime -1 (inclusive)\n",
    "    #c is maximum possible value for the hash code + 1\n",
    "    #next_prime is prime number that is greater than max possible value of x \n",
    "    \n",
    "    next_prime = get_next_prime(numrows-1)\n",
    "    a = random.choices(range(1,next_prime,2),k=numhashfunctions)\n",
    "    b = random.sample(list(range(0,next_prime)),numhashfunctions)\n",
    "    c = numrows\n",
    "    \n",
    "    for i in range(numrows):\n",
    "        for j in range(numhashfunctions):\n",
    "            hashvalues.append((a[j]*i + b[j])% c)\n",
    "        \n",
    "    return np.array(hashvalues).reshape(numrows,numhashfunctions)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute minhash following the faster algorithm from the lecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMinHashSignatureMatrix(binary_matrix, hash_val_matrix,n_doc):\n",
    "    #return minhash signature matrix\n",
    "    print('Creating Signature Matrix...')\n",
    "    minhash_signature = np.array(np.ones((hash_val_matrix.shape[1],n_doc)) * np.inf)\n",
    "\n",
    "    for key in binary_matrix:\n",
    "        for index in binary_matrix[key]:\n",
    "            minhash_signature[:,index] = np.minimum(minhash_signature[:,index],hash_val_matrix[key])\n",
    "    \n",
    "    #replace the infinity to max values in the matrix +1 just to avoid problem in the mathematic steps further\n",
    "    #minhash_signature[minhash_signature == np.inf] = minhash_signature[minhash_signature!=np.inf].max()+1\n",
    "    \n",
    "    return minhash_signature\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash signature bands into buckets. Find a way to combine all the signature values in a band and hash them into a number of buckets ususally very high.\n",
    "* Easiest way is to add all the signature values in the bucket and use a similar hash function like before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLSH(signature_matrix, num_bands, num_buckets): #removing hashfunctions from the parameter \n",
    "    #return lsh buckets or hash table\n",
    "    print('Hashing into buckets...')\n",
    "    buckets = {}\n",
    "    \n",
    "    r = int(signature_matrix.shape[0]/num_bands)\n",
    "    \n",
    "    #using same universal hashing\n",
    "    next_prime = get_next_prime(r-1)\n",
    "    a = random.choices(range(1,next_prime,2),k=r)\n",
    "    b = random.randint(0,next_prime-1)\n",
    "    c = num_buckets\n",
    "    \n",
    "    for i in range(num_bands):\n",
    "        print('band',i, 'of total' ,num_bands,'bands')\n",
    "        each_band = signature_matrix[i*r:(i*r)+r]\n",
    "        bucket_nos = ((np.dot(a,each_band)+b)%c).astype(int)\n",
    "        print('done hashing band',i,'into buckets')\n",
    "        for j in range(len(bucket_nos)):\n",
    "            if bucket_nos[j] in buckets:\n",
    "                buckets[bucket_nos[j]].append(j)\n",
    "            else:\n",
    "                buckets[bucket_nos[j]]= [j]\n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune parameters to make sure the threshold is appropriate.\n",
    "## plot the probability of two similar items falling in same bucked for different threshold values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_frequency..\n",
      "get_sets of articles\n",
      "sorting index\n",
      "Select top 10000 most frequent n-grams\n",
      "Creating binary matrix\n",
      "Creating Signature Matrix...\n",
      "Hashing into buckets...\n",
      "band 0 of total 20 bands\n",
      "done hashing band 0 into buckets\n",
      "band 1 of total 20 bands\n",
      "done hashing band 1 into buckets\n",
      "band 2 of total 20 bands\n",
      "done hashing band 2 into buckets\n",
      "band 3 of total 20 bands\n",
      "done hashing band 3 into buckets\n",
      "band 4 of total 20 bands\n",
      "done hashing band 4 into buckets\n",
      "band 5 of total 20 bands\n",
      "done hashing band 5 into buckets\n",
      "band 6 of total 20 bands\n",
      "done hashing band 6 into buckets\n",
      "band 7 of total 20 bands\n",
      "done hashing band 7 into buckets\n",
      "band 8 of total 20 bands\n",
      "done hashing band 8 into buckets\n",
      "band 9 of total 20 bands\n",
      "done hashing band 9 into buckets\n",
      "band 10 of total 20 bands\n",
      "done hashing band 10 into buckets\n",
      "band 11 of total 20 bands\n",
      "done hashing band 11 into buckets\n",
      "band 12 of total 20 bands\n",
      "done hashing band 12 into buckets\n",
      "band 13 of total 20 bands\n",
      "done hashing band 13 into buckets\n",
      "band 14 of total 20 bands\n",
      "done hashing band 14 into buckets\n",
      "band 15 of total 20 bands\n",
      "done hashing band 15 into buckets\n",
      "band 16 of total 20 bands\n",
      "done hashing band 16 into buckets\n",
      "band 17 of total 20 bands\n",
      "done hashing band 17 into buckets\n",
      "band 18 of total 20 bands\n",
      "done hashing band 18 into buckets\n",
      "band 19 of total 20 bands\n",
      "done hashing band 19 into buckets\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#Parameters to tune\n",
    "n_bands =20\n",
    "n_rows =10\n",
    "n_hash = n_bands*n_rows\n",
    "num_buckets = 200000\n",
    "K = 3 #for the ngrams\n",
    "\n",
    "# Get all the n_grams for each articles\n",
    "articles_ngram = getNgrams(articles.iloc[:,0].to_list(),K)\n",
    "#construct binary_matrix\n",
    "binary_matrix,nrow = getBinaryMatrix(articles_ngram)\n",
    "\n",
    "hash_values = getHashFunctionValues(nrow,n_hash)\n",
    "signature_matrix = getMinHashSignatureMatrix(binary_matrix,hash_values,articles.shape[0])\n",
    "buckets = getLSH(signature_matrix,n_bands,num_buckets)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the best parameters and get nearest neighbors of each articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the nearest neibhors of each document to submissions.csv (comma separated, first column is the current document followed by a list of nearest neighbors) file and get the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBinaryMatrix(articles, n = 2):\n",
    "\tbinMatrix = {}\n",
    "\tseenShingles = {}\n",
    "\tfor i in range(articles.shape[0]):\n",
    "\t\tarticle = articles[i]\n",
    "\t\tshingleGenerator = getNgrams(article, n)\n",
    "\t\tfor shingle in shingleGenerator:\n",
    "\t\t\tif shingle in seenShingles:\n",
    "\t\t\t\tshingleIndex = seenShingles[shingle]\n",
    "\t\t\telse:\n",
    "\t\t\t\tshingleIndex = len(seenShingles)\n",
    "\t\t\t\tseenShingles[shingle] = shingleIndex\n",
    "\t\t\tif shingleIndex not in binMatrix:\n",
    "\t\t\t\tbinMatrix[shingleIndex] = []\n",
    "\t\t\tbinMatrix[shingleIndex].append(i)\n",
    "\treturn binMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "y_pred = [0, 2, 1, 3]\n",
    "y_true = [0, 1, 2, 3]\n",
    "jaccard_similarity_score(y_true, y_pred)\n",
    "\n",
    "#jaccard_similarity_score(y_true, y_pred, normalize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
